{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d9098b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Dataset\n",
    "\n",
    "https://www-genesis.destatis.de/datenbank/online/statistic/21311/table/21311-0003\n",
    "\n",
    "Number of students in Germany by subject of study, nationality, gender from 2018-2024. I will focus on the final year 2023/24 for a start. (Will I?)\n",
    "\n",
    "Check this document for official practice of subject codes and subject cluster classifications: https://www.destatis.de/DE/Methoden/Klassifikationen/Bildung/studenten-pruefungsstatistik.pst_all?__blob=publicationFile&v=12\n",
    "\n",
    "## Questions \n",
    "\n",
    "1. What was the total number of students in Germany in 2023/24?\n",
    "2. What were the 10 subjects with the highest number of students in 2023/24?\n",
    "3. How was the gender distribution of students in 2023/24?\n",
    "4. How was the gender distribution in the 5 most studied subjects?\n",
    "5. What were the top subjects by gender?\n",
    "6. Which were the top 5 subjects studied by non-citizens? \n",
    "7. (Sort the subjects into clusters and provide a cluster identifier to the dataframe.) How are the student numbers distributed across subject clusters?\n",
    "8. How does the number of students change over the time period by cluster?\n",
    "9. How does the number of students change over the time period for language related subjects?\n",
    "10. How does the number of students change for linguistics in a narrow perspective?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c376b8f2",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aac1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02c48c",
   "metadata": {},
   "source": [
    "## Load dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3d3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields of study, all Germany 2018-2024\n",
    "# using the non-flat csv\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21311/table/21311-0003\n",
    "stud = pd.read_csv('./datasets/raw/21311-0003_de_flat_allstudents.csv',sep=';')\n",
    "\n",
    "# for alternative table with data per state see:\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21311/table/21311-0006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de75c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional datasets\n",
    "# freshers by course of study\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21311/table/21311-0012\n",
    "freshers = pd.read_csv('./datasets/raw/21311-0012_de_flat_freshers.csv',sep=';')\n",
    "\n",
    "# employees at higher education institutions by subject group\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21341/table/21341-0002\n",
    "pers = pd.read_csv('./datasets/raw/21341-0002_de_flat_personnel.csv',sep=';')\n",
    "\n",
    "\n",
    "# professors by subject group\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21341/table/21341-0003\n",
    "prof = pd.read_csv('./datasets/raw/21341-0003_de_flat_profs.csv',sep=';')\n",
    "\n",
    "\n",
    "# exams by subject\n",
    "# https://www-genesis.destatis.de/datenbank/online/statistic/21321/table/21321-0003\n",
    "exams = pd.read_csv('./datasets/raw/21321-0003_de_flat_exams.csv',sep=';')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e2dbd",
   "metadata": {},
   "source": [
    "## Creating a list of relations for subjects, subject clusters and subject groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b453b83",
   "metadata": {},
   "source": [
    "Prompt for data extraction from pst_all (request for csv in previous context) at Claude. Initially, I tried ChatGPT, but it struggled with the pst_all format (presumably the three columns) and hit its limit while processing.\n",
    "\n",
    "> **Prompt**:\n",
    ">\n",
    "> The uploaded pst_all contains three columns per page in the main text body. The document is in German. Do not change any of the subject titles, but drop any footnote markers. Extract the following data into a csv-file:\n",
    "> - \"FÃ¤chergruppe\" into the columns 'subj_group_code' for the numerical code and 'subj_group_name' for the name (e.g. Geisteswissenschaften)\n",
    "> - \"Studienbereich\" (underlined in the pst_all) into columns 'subj_cluster_code' and 'subj_cluster_name' respectively\n",
    "> - \"Studienfach\" into columns 'subj_code' and 'subj_name'\n",
    ">\n",
    "> For each of the three levels, also provide a column '..._name_eng' with an approximate English translation for the respective German '..._name'. The translation need not be literal, but can consider more common English terminology as long as the content is coherent. Make sure to use the same translation for any recurring term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e732a",
   "metadata": {},
   "source": [
    "**To note for future reference. I had originally suspected a dictionary/JSON would be the simplest representation of the data (albeit requiring some post-processing to generate a table later), but ChatGPT had suggested I generate a csv in an earlier chat. However, it may actually have considered the ease with which I would be able to use the data rather than its own computational efficiency.**\n",
    "\n",
    "(Note that I was not able to use this prompt in the same chat that generated the csv-file due to length restrictions on the chat. So I am still not quite sure if repeating values may have been stored because this answer is a bit more general.)\n",
    "\n",
    "> **Prompt**\n",
    "> \n",
    "> I just had you create a csv file with slightly under 300 rows of data extracted from a pst_all involving an underlying nested structure of subject groups and their codes, subject clusters the groups consist of including their numerical code and subjects including their code. Since the pst_all was in German, I additionally asked for an additional column in the csv file with an English translation for each name column of the three structural levels. For the higher level values, there was naturally a lot of repetition due to the large number of subjects. For future reference, in such contexts, do the repeating names and translations have to be recomputed for every line of the csv? Would a different output formatting have been less computationally expensive for you (i.e. using less energy and/or tokens), e.g. as a python dictionary?\n",
    "\n",
    "> **Claude reply**:\n",
    "> \n",
    "> When working with hierarchical data like you described, you're right to consider computational efficiency, especially for a large dataset with repetitive elements.\n",
    "> \n",
    "> For your specific case with grouped subject data in German/English:\n",
    "> \n",
    "> CSV format is indeed less efficient when dealing with hierarchical data with repetition. Each time a higher-level group value appears in multiple rows, I needed to:\n",
    "> 1. Store that repeated text in each row\n",
    "> 2. Translate the same text multiple times (or recall the previous translation)\n",
    "> \n",
    "> A more efficient approach would have been:\n",
    "> \n",
    "> **Nested data structures** like a Python dictionary or JSON would better preserve the hierarchy and eliminate repetition:\n",
    "> \n",
    "> ```\n",
    "> {\n",
    ">   \"group_code1\": {\n",
    ">     \"name_de\": \"Gruppe Name\",\n",
    ">     \"name_en\": \"Group Name\",\n",
    ">     \"clusters\": {\n",
    ">       \"cluster_code1\": {\n",
    ">         \"name_de\": \"Cluster Name\",\n",
    ">         \"name_en\": \"Cluster Name\",\n",
    ">         \"subjects\": [\n",
    ">           {\"code\": \"subj1\", \"name_de\": \"Fach1\", \"name_en\": \"Subject1\"},\n",
    ">           {\"code\": \"subj2\", \"name_de\": \"Fach2\", \"name_en\": \"Subject2\"}\n",
    ">         ]\n",
    ">       }\n",
    ">     }\n",
    ">   }\n",
    "> }\n",
    "> ```\n",
    "> \n",
    "> This structure would:\n",
    "> - Store each name/translation only once\n",
    "> - Preserve the hierarchy naturally\n",
    "> - Require significantly fewer tokens to represent\n",
    "> - Be more computationally efficient to generate\n",
    "> - Use less memory/energy overall\n",
    "> \n",
    "> If you need to work with this data in the future, requesting structured formats that match the natural hierarchy of your data will be both more efficient for AI processing and likely more useful for your subsequent data handling.\n",
    "\n",
    "\n",
    "So for the future, generating a JSON or dictionary for this type of data and then do local post-processing might be the more computationally effective and responsible option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70484200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading subject code lookup table\n",
    "subjectcodes = pd.read_csv('./datasets/german_subject_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf959f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6cc68",
   "metadata": {},
   "source": [
    "## Student data total exploration\n",
    "\n",
    "*This subsection outlines my original data exploration to understand the source data format. The cells are commented out, but kept for documentation. In the next subsection further below [Create Cleaning function](#create-cleaning-function) I am going defining a function for automated data cleaning and reformatting before combining some of the source tables as appropriate to create the working data frames.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14318b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used, kept for documentation\n",
    "#stud_nofl = pd.read_csv('./datasets/21311-0003_de_2018-2024_GER.csv',sep=';')\n",
    "#stud_nofl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b0102",
   "metadata": {},
   "source": [
    "The non-flat csv seems to be aimed at presentation in spreadsheet editors. Reformating might be possible, but potentially complex. Let's use the flat-csv instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215f9fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da6420",
   "metadata": {},
   "source": [
    "The data structure is also rather complex, which probably makes sense for standardisation purposes at the Statistisches Bundesamt, but for present purposes it makes sense to create a more transparent dataframe. The advantage to the non-flat csv is that every line seems to cleanly correspond to a datapoint. Labels are intermingled, so some cleanup will be required.\n",
    "\n",
    "The value of `4_variable_attribute_label` also hints at a problem to be encountered later, namely shifts in the subject code allocation. That course of study seems to have been assigned to a new code in 2020; there are likely to be other datapoints with this issue, to be checked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecb27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a883cba",
   "metadata": {},
   "source": [
    "### Variables to keep and rename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1639b3",
   "metadata": {},
   "source": [
    "**Rough overview of columns**\n",
    "\n",
    "```python\n",
    "allcols = ['statistics_code', 'statistics_label',                                                                   # identifier of statistic\n",
    "            'time_code', 'time_label', 'time',                                                                      # time label \n",
    "            '1_variable_code', '1_variable_label', '1_variable_attribute_code', '1_variable_attribute_label',       # datascope\n",
    "            '2_variable_code', '2_variable_label', '2_variable_attribute_code', '2_variable_attribute_label',       # nationality\n",
    "            '3_variable_code', '3_variable_label', '3_variable_attribute_code', '3_variable_attribute_label',       # gender\n",
    "            '4_variable_code', '4_variable_label', '4_variable_attribute_code', '4_variable_attribute_label',       # subject\n",
    "            'value', 'value_unit', 'value_variable_code', 'value_variable_label']                                   # value = number of students\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b0158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that variable 1 only has one distinct value, signifying that the scope of the data is all of Germany\n",
    "# stud['1_variable_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e3137",
   "metadata": {},
   "source": [
    "The identifiers for the statistic can be dropped, as can the code and label for time. Since we only include data for all of Germany for now, all `1_variable` columns can also be removed.\n",
    "The general strategy for the next two variables is to only keep the `[23]_variable_attribute_code`s. They contain NaN for the total values, which will allow relatively easy filtering later to remove these \"totals\" lines to avoid double counting issues.\n",
    "For variable 4, we keep `variable_attribute_code` and `variable_attribute_label`. The former may be helpful for clustering subjects later on, the latter is more transparent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a056b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_cols = ['statistics_code', 'statistics_label', \n",
    "#             'time_code', 'time_label',\n",
    "#             '1_variable_code', '1_variable_label', '1_variable_attribute_code', '1_variable_attribute_label',       # datascope\n",
    "#             '2_variable_code', '2_variable_label', '2_variable_attribute_label',       # \n",
    "#             '3_variable_code', '3_variable_label', '3_variable_attribute_label',\n",
    "#             '4_variable_code', '4_variable_label', \n",
    "#             'value_unit', 'value_variable_code', 'value_variable_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767a177",
   "metadata": {},
   "source": [
    "\n",
    "Below we identify the columns that should be kept and create a dictionary for a more transparent naming scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e42df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stud.time.unique()      # checking unique values in `time`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29151d32",
   "metadata": {},
   "source": [
    "\n",
    "`time` corresponds to the year of record. Can be mapped to plain year for simplicity. Currently, '2018-10P6M' presumably indicates the academic year 2018/2019, which began in October 2018. This could be mapped to the integer 2018 (or '2018/19', but the year of start should be a sufficient identifier). These are effectively categorical variables, but treating them as integer is more memory efficient and fine for sorting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b276ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colname_remap = {\n",
    "#     'time': 'acyear',\n",
    "#     '2_variable_attribute_code': 'nationality',\n",
    "#     '3_variable_attribute_code': 'gender',\n",
    "#     '4_variable_attribute_code': 'subj_code',\n",
    "#     '4_variable_attribute_label': 'subj_name',\n",
    "#     'value': 'stud_count'\n",
    "#     }      # dict for remapping the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce6ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all = stud.drop(remove_cols,axis='columns')\n",
    "# st_all = st_all.rename(columns=colname_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6268c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd92f83",
   "metadata": {},
   "source": [
    "Now, we need to make sure `stud_count` is an integer and simplify `acyear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4841040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check non-digit values for `stud_count`\n",
    "# st_all.loc[st_all.stud_count.str.isdigit() == False,'stud_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbe20437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all.loc[st_all.stud_count == '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801666dd",
   "metadata": {},
   "source": [
    "Currently, zero values are represented by '-', so we replace all instances of '-' by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ac6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all instances of '-' in stud_count by 0\n",
    "# st_all.stud_count = st_all.stud_count.str.replace('-','0')\n",
    "# st_all.loc[st_all.stud_count == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24dd43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can cast as type int\n",
    "# st_all.stud_count = st_all.stud_count.astype(int)\n",
    "# st_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "427c805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c31b5",
   "metadata": {},
   "source": [
    "To take care of the year, we can just split at the hyphen to keep only the year and then cast as int as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61756c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all.acyear = st_all.acyear.str.split('-').str[0].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44221b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadfddf",
   "metadata": {},
   "source": [
    "### Removing totals columns\n",
    "\n",
    "*This can actually be achieved by changing selections at dataset download. I leave the code below for documentation, but comment it out.*\n",
    "\n",
    "Now all datatypes should be fine, let's check that we can indeed remove the rows with NULL for `gender` or `nationality`. These should correspond to the totals, which we can easily reconstruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e5c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.loc[(st_all.subj_code =='SF142') & (st_all.acyear == 2018)].sort_values(['nationality','gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27042d",
   "metadata": {},
   "source": [
    "If the concept is right, the sum of all stud_counts where neither `gender` nor `nationality` is na should be 1088."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31c4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.loc[(st_all.subj_code =='SF142') & (st_all.acyear == 2018) & (st_all.nationality.isna() == False) & (st_all.gender.isna() == False)].stud_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1ecda",
   "metadata": {},
   "source": [
    "This checks out, so we can (and should) indeed remove all rows with NaN in either of those two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5316b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd28732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all = st_all.dropna(subset=['gender','nationality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dc46d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cf279c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f44b7c",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "Great, no na values left! The dataset should be usable now (barring further extension for subject clustering). Let's reset the index and save the cleaned up version for easier access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22b53cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st_all.reset_index(drop=True,inplace=True)\n",
    "#st_all.to_csv('./datasets/GER_2018_2023_students_all_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aabd1b",
   "metadata": {},
   "source": [
    "## Create cleaning function\n",
    "\n",
    "Based on findings above, I create a function to encapsulate cleaning this particular dataformat - I have at least one other student dataset after all. I leave the code above intact for documentation purposes.\n",
    "\n",
    "Different tables from Statistisches Bundesamt might require further adaptations of function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and saving function\n",
    "def clean_dat(in_df, dropcols, rencols, csvname='',complexdate=False,insgesamt=False):\n",
    "    '''Function to streamline cleaning student data from Statistisches Bundesamt\n",
    "    \n",
    "    in_df: the input dataframe\n",
    "    dropcols: list of column names to drop\n",
    "    rencols: dictionary of column name changes\n",
    "    csvname: string for the path and name of the cleaned csv file\n",
    "    '''\n",
    "    df = in_df.copy()\n",
    "    \n",
    "    \n",
    "    # replace all instances of '-' in stud_count by '0' and cast as int\n",
    "    # doing this before renaming to slightly increase chances of portability of code\n",
    "    # (still assumes that column 'value' exists and works the same)\n",
    "    if 'value' in df.columns:\n",
    "        df.value = df.value.str.replace('-','0').astype(int)\n",
    "    else:\n",
    "        print(f'Column `value` not found in dataframe {in_df}')\n",
    "    \n",
    "    # transform `time` to a plain year integer, corresponding to starting date of academic year\n",
    "    if 'time' in df.columns:\n",
    "        if complexdate:\n",
    "            df.time = df.time.str.split('-').str[0].astype(int)\n",
    "        else:                                                       # if complexdate flag is not set, simply cast `time` to int\n",
    "            df.time = df.time.astype(int)\n",
    "    else:\n",
    "        print(f'Column `time` not found in dataframe {in_df}')\n",
    "\n",
    "    # removing columns\n",
    "    df = df.drop(dropcols,axis='columns')\n",
    "    \n",
    "    # renaming columns\n",
    "    df = df.rename(columns=rencols)\n",
    "    \n",
    "    # special check for tables with na values due to datarows with na in subj_grp_code (the \"Insgesamt\"/total rows we don't need)\n",
    "    if insgesamt:\n",
    "        df.dropna(subset=['subj_grp_code'],inplace=True)\n",
    "\n",
    "    \n",
    "    # reset index\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    # optionally save csv file if path is provided\n",
    "    if csvname:                                          \n",
    "        df.to_csv(csvname)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26a59b",
   "metadata": {},
   "source": [
    "## Merging and cleaning student data\n",
    "\n",
    "Combining the datasets for students by subject overall and freshers.\n",
    "Then apply the cleaning function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152d18e",
   "metadata": {},
   "source": [
    "First, create identifying columns for the stud and freshers dataframes. (One could use the `value_variable_label` or `code`, but the values are a bit unwieldy, so I'll just create new columns and continue to get rid of these.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bbb17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud['subgroup'] = 'stud_all'\n",
    "freshers['subgroup'] = 'stud_y1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8759afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list and dictionary for data cleaning\n",
    "stud_drop = ['statistics_code', 'statistics_label', \n",
    "            'time_code', 'time_label',\n",
    "            '1_variable_code', '1_variable_label', '1_variable_attribute_code', '1_variable_attribute_label',   \n",
    "            '2_variable_code', '2_variable_label', '2_variable_attribute_label',     \n",
    "            '3_variable_code', '3_variable_label', '3_variable_attribute_label',\n",
    "            '4_variable_code', '4_variable_label', \n",
    "            'value_unit', 'value_variable_code', 'value_variable_label']\n",
    "\n",
    "stud_remap = {\n",
    "    'time': 'year',\n",
    "    '2_variable_attribute_code': 'nationality',\n",
    "    '3_variable_attribute_code': 'gender',\n",
    "    '4_variable_attribute_code': 'subj_code',\n",
    "    '4_variable_attribute_label': 'subj_name',\n",
    "    'value': 'number'\n",
    "    }      # dict for remapping the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1055af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = clean_dat(pd.concat([stud,freshers]),stud_drop,stud_remap,'./datasets/clean_stud_GER_2018_2023.csv',complexdate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64ecb01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bbc6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9791867",
   "metadata": {},
   "source": [
    "Great, concatenation and cleaning seems to have worked as intended.\n",
    "\n",
    "Student dataset is clean in `dfs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ad071",
   "metadata": {},
   "source": [
    "## Exam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1adf7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e773130",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_drop = ['statistics_code', 'statistics_label', \n",
    "            'time_code', 'time_label',\n",
    "            '1_variable_code', '1_variable_label', '1_variable_attribute_code', '1_variable_attribute_label',   \n",
    "            '2_variable_code', '2_variable_label', '2_variable_attribute_label',     \n",
    "            '3_variable_code', '3_variable_label', '3_variable_attribute_label',\n",
    "            '4_variable_code', '4_variable_label', '4_variable_attribute_label',\n",
    "            '5_variable_code', '5_variable_label',\n",
    "            'value_unit', 'value_variable_code', 'value_variable_label']\n",
    "\n",
    "ex_remap = {\n",
    "    'time': 'year',\n",
    "    '2_variable_attribute_code': 'nationality',\n",
    "    '3_variable_attribute_code': 'gender',\n",
    "    '4_variable_attribute_code': 'passed',\n",
    "    '5_variable_attribute_code': 'subj_code',\n",
    "    '5_variable_attribute_label': 'subj_name',\n",
    "    'value': 'number'\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "187ae456",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfex = clean_dat(exams,ex_drop,ex_remap,'./datasets/clean_exams_GER_2018_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e333d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfex.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d8ef751",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc16683",
   "metadata": {},
   "source": [
    "Exam data is student-related and considering that people typically have to be registered students to take exams, they're probably a subset of the `stud_all` subgroup of the dfs (students) dataset. However, I'll keep the dataset separate for now, not least because of the additional `passed` property.\n",
    "\n",
    "Exam data is clean in dataframe `dfex`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374c184",
   "metadata": {},
   "source": [
    "## Combining personnel data\n",
    "\n",
    "Similar to the student datasets above, the general personnel data and the professorial counts are in a subset relation, so we'll combine them with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8af3c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers['subgroup'] = 'p_all'\n",
    "prof['subgroup'] = 'p_prof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "514e5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting personnel data structure to identify column structure\n",
    "pers.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "894b4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cd3928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list and dict for column dropping and renaming\n",
    "pers_drop = [\n",
    "    'statistics_code', 'statistics_label', 'time_code', 'time_label',\n",
    "    '1_variable_code', '1_variable_label',\n",
    "       '1_variable_attribute_code', '1_variable_attribute_label',\n",
    "       '2_variable_code', '2_variable_label', '3_variable_code', '3_variable_label',\n",
    "        '3_variable_attribute_label',\n",
    "       'value_unit', 'value_variable_code', 'value_variable_label'\n",
    "]\n",
    "\n",
    "pers_rename ={\n",
    "    'time': 'year',\n",
    "    '2_variable_attribute_label': 'subj_grp_name',\n",
    "    '2_variable_attribute_code': 'subj_grp_code',\n",
    "    '3_variable_attribute_code': 'gender',\n",
    "    'value': 'number'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59cfb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = clean_dat(pd.concat([pers,prof]),pers_drop,pers_rename,'./datasets/clean_personnel_GER_2018_2023.csv',insgesamt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6bc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keeping this code here for documentation, cleaning implemented in function `clean_dat` now\n",
    "\n",
    "# display(dfp.isna().sum())\n",
    "# display(dfp.loc[dfp.subj_grp_code.isna()])\n",
    "# display(dfp.loc[dfp.subj_grp_name=='Insgesamt'])\n",
    "\n",
    "# # The problem is fundamentally the same in both `subj_grp_code` and `subj_grp_name` columns, we don't need these \"Total\" rows, so drop them.  \n",
    "# dfp.dropna(subset=['subj_grp_code'],inplace=True)\n",
    "# dfp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70e424fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebb2ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c98a29",
   "metadata": {},
   "source": [
    "`pers_cl` is now clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ade6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.loc[dfp.subgroup == 'p_prof','subj_grp_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94b5fc",
   "metadata": {},
   "source": [
    "# Further EDA and processing on cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3200f70",
   "metadata": {},
   "source": [
    "dfp.loc[dfp.subgroup == 'p_prof','subj_grp_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab280933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61deb8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b095bf4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
